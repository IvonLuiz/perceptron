{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x1 e x2: dados de entrada.\n",
    "* w1 e w2: pesos que serão multiplicados pelos dados de entrada.\n",
    "* b: bias, também é um peso, porém é chamado de “peso livre” por não ser multiplicado com nenhuma outra variável.\n",
    "* z: soma das multiplicações e adição do bias e posteriormente aplicado a função de ativação, que é responsável pela saída do dado processado.\n",
    "* função de ativação: função matemática responsável por produzir o dado binário de saída. Normalmente na função de ativação é utilizada a função degrau, onde se a saída da função for maior ou igual a 0, o resultado produzido será 1, se for menor, resultará em 0.\n",
    "* erro: valor esperado subtraído do valor predito pelo modelo.\n",
    "* taxa de aprendizagem: taxa e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        # Random weights\n",
    "        self.w = np.random.rand(input_size)\n",
    "        self.b = np.random.random()\n",
    "        \n",
    "    def step(self, x):\n",
    "        # if x > 0:\n",
    "        #     return 1\n",
    "        # return 0\n",
    "        # return x\n",
    "        return np.heaviside(x, 0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = np.dot(inputs, self.w.T) + self.b\n",
    "        output = self.step(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def train(self, inputs, outputs, lr, epochs):\n",
    "        outputs = outputs.T\n",
    "        loss_hist = []\n",
    "\n",
    "        for e in range(epochs):\n",
    "            predictions = self.forward(inputs)\n",
    "\n",
    "            error = outputs - predictions\n",
    "            loss = self.loss(outputs, predictions)\n",
    "            self.w += lr * np.dot(error, inputs).flatten() \n",
    "            self.b += lr * np.sum(error)\n",
    "\n",
    "            print(f\"Epoch {e+1}/{epochs}, Weights: {np.round(self.w, 2)}, Bias: {np.round(self.b, 2)} Loss: {loss}\")\n",
    "\n",
    "        return loss_hist\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        # MSE Loss\n",
    "        loss = np.mean((y_pred - y_true) ** 2)\n",
    "        return loss\n",
    "\n",
    "    # def activation(self, inputs):\n",
    "    #     sigmoid = 1 / (1 + np.exp(-inputs))\n",
    "    #     return sigmoid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Cada item da lista dos dados de entrada representa as duas entradas lógicas\n",
    "# A variável outputs representa a saída esperada da operação lógica, aqui no caso representa a tabela OR\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.float64([[0], [1], [1], [1]])\n",
    "\n",
    "print(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Weights: [0.31 0.18], Bias: 0.4 Loss: 0.25\n",
      "Epoch 2/50, Weights: [0.31 0.18], Bias: 0.39 Loss: 0.25\n",
      "Epoch 3/50, Weights: [0.31 0.18], Bias: 0.38 Loss: 0.25\n",
      "Epoch 4/50, Weights: [0.31 0.18], Bias: 0.37 Loss: 0.25\n",
      "Epoch 5/50, Weights: [0.31 0.18], Bias: 0.36 Loss: 0.25\n",
      "Epoch 6/50, Weights: [0.31 0.18], Bias: 0.35 Loss: 0.25\n",
      "Epoch 7/50, Weights: [0.31 0.18], Bias: 0.34 Loss: 0.25\n",
      "Epoch 8/50, Weights: [0.31 0.18], Bias: 0.33 Loss: 0.25\n",
      "Epoch 9/50, Weights: [0.31 0.18], Bias: 0.32 Loss: 0.25\n",
      "Epoch 10/50, Weights: [0.31 0.18], Bias: 0.31 Loss: 0.25\n",
      "Epoch 11/50, Weights: [0.31 0.18], Bias: 0.3 Loss: 0.25\n",
      "Epoch 12/50, Weights: [0.31 0.18], Bias: 0.29 Loss: 0.25\n",
      "Epoch 13/50, Weights: [0.31 0.18], Bias: 0.28 Loss: 0.25\n",
      "Epoch 14/50, Weights: [0.31 0.18], Bias: 0.27 Loss: 0.25\n",
      "Epoch 15/50, Weights: [0.31 0.18], Bias: 0.26 Loss: 0.25\n",
      "Epoch 16/50, Weights: [0.31 0.18], Bias: 0.25 Loss: 0.25\n",
      "Epoch 17/50, Weights: [0.31 0.18], Bias: 0.24 Loss: 0.25\n",
      "Epoch 18/50, Weights: [0.31 0.18], Bias: 0.23 Loss: 0.25\n",
      "Epoch 19/50, Weights: [0.31 0.18], Bias: 0.22 Loss: 0.25\n",
      "Epoch 20/50, Weights: [0.31 0.18], Bias: 0.21 Loss: 0.25\n",
      "Epoch 21/50, Weights: [0.31 0.18], Bias: 0.2 Loss: 0.25\n",
      "Epoch 22/50, Weights: [0.31 0.18], Bias: 0.19 Loss: 0.25\n",
      "Epoch 23/50, Weights: [0.31 0.18], Bias: 0.18 Loss: 0.25\n",
      "Epoch 24/50, Weights: [0.31 0.18], Bias: 0.17 Loss: 0.25\n",
      "Epoch 25/50, Weights: [0.31 0.18], Bias: 0.16 Loss: 0.25\n",
      "Epoch 26/50, Weights: [0.31 0.18], Bias: 0.15 Loss: 0.25\n",
      "Epoch 27/50, Weights: [0.31 0.18], Bias: 0.14 Loss: 0.25\n",
      "Epoch 28/50, Weights: [0.31 0.18], Bias: 0.13 Loss: 0.25\n",
      "Epoch 29/50, Weights: [0.31 0.18], Bias: 0.12 Loss: 0.25\n",
      "Epoch 30/50, Weights: [0.31 0.18], Bias: 0.11 Loss: 0.25\n",
      "Epoch 31/50, Weights: [0.31 0.18], Bias: 0.1 Loss: 0.25\n",
      "Epoch 32/50, Weights: [0.31 0.18], Bias: 0.09 Loss: 0.25\n",
      "Epoch 33/50, Weights: [0.31 0.18], Bias: 0.08 Loss: 0.25\n",
      "Epoch 34/50, Weights: [0.31 0.18], Bias: 0.07 Loss: 0.25\n",
      "Epoch 35/50, Weights: [0.31 0.18], Bias: 0.06 Loss: 0.25\n",
      "Epoch 36/50, Weights: [0.31 0.18], Bias: 0.05 Loss: 0.25\n",
      "Epoch 37/50, Weights: [0.31 0.18], Bias: 0.04 Loss: 0.25\n",
      "Epoch 38/50, Weights: [0.31 0.18], Bias: 0.03 Loss: 0.25\n",
      "Epoch 39/50, Weights: [0.31 0.18], Bias: 0.02 Loss: 0.25\n",
      "Epoch 40/50, Weights: [0.31 0.18], Bias: 0.01 Loss: 0.25\n",
      "Epoch 41/50, Weights: [0.31 0.18], Bias: 0.0 Loss: 0.25\n",
      "Epoch 42/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.25\n",
      "Epoch 43/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 44/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 45/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 46/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 47/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 48/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 49/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n",
      "Epoch 50/50, Weights: [0.31 0.18], Bias: -0.01 Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "percp = Perceptron(2)\n",
    "# Passamos os dados de entrada e de saída, junto com a taxa de aprendizagem e a quantidade de épocas de treinamento\n",
    "hist = percp.train(inputs, outputs, 0.01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "pred_1 = percp.forward([0, 0])\n",
    "pred_2 = percp.forward([0, 1])\n",
    "pred_3 = percp.forward([1, 0])\n",
    "pred_4 = percp.forward([1, 1])\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(pred_1)\n",
    "print(pred_2)\n",
    "print(pred_3)\n",
    "print(pred_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
